{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "from argparse import ArgumentParser\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from src.models.model_factory import build_model, build_criterion\n",
    "from src.data.data_factory import build_dataloaders\n",
    "from src.utils.configs import get_default_configuration, load_config\n",
    "from src.utils.confusion import BinaryConfusionMatrix\n",
    "from src.data.nuscenes.utils import NUSCENES_CLASS_NAMES\n",
    "from src.data.argoverse.utils import ARGOVERSE_CLASS_NAMES\n",
    "from src.utils.visualise import colorise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(dataloader, model, criterion, optimiser, summary, config, epoch):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    # Compute prior probability of occupancy\n",
    "    prior = torch.tensor(config.prior)\n",
    "    prior_log_odds = torch.log(prior / (1 - prior))\n",
    "\n",
    "    # Initialise confusion matrix\n",
    "    confusion = BinaryConfusionMatrix(config.num_class)\n",
    "    \n",
    "    # Iterate over dataloader\n",
    "    iteration = (epoch - 1) * len(dataloader)\n",
    "    for i, batch in enumerate(tqdm(dataloader)):\n",
    "\n",
    "        # Move tensors to GPU\n",
    "        if len(config.gpus) > 0:\n",
    "            batch = [t.cuda() for t in batch]\n",
    "        \n",
    "        # Predict class occupancy scores and compute loss\n",
    "        image, calib, labels, mask = batch\n",
    "        if config.model == 'ved':\n",
    "            logits, mu, logvar = model(image)\n",
    "            loss = criterion(logits, labels, mask, mu, logvar)\n",
    "        else:\n",
    "            logits = model(image, calib)\n",
    "            loss = criterion(logits, labels, mask)\n",
    "\n",
    "\n",
    "        # Compute gradients and update parameters\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "        # Update confusion matrix\n",
    "        scores = logits.cpu().sigmoid()  \n",
    "        confusion.update(scores > config.score_thresh, labels, mask)\n",
    "\n",
    "        # Update tensorboard\n",
    "        if i % config.log_interval == 0:\n",
    "            summary.add_scalar('train/loss', float(loss), iteration)\n",
    "\n",
    "        # Visualise\n",
    "        if i % config.vis_interval == 0:\n",
    "            visualise(summary, image, scores, labels, mask, iteration, \n",
    "                      config.train_dataset, split='train')\n",
    "                \n",
    "        iteration += 1\n",
    "\n",
    "    # Print and record results\n",
    "    display_results(confusion, config.train_dataset)\n",
    "    log_results(confusion, config.train_dataset, summary, 'train', epoch)\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(dataloader, model, criterion, summary, config, epoch):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # Compute prior probability of occupancy\n",
    "    prior = torch.tensor(config.prior)\n",
    "    prior_log_odds = torch.log(prior / (1 - prior))\n",
    "\n",
    "    # Initialise confusion matrix\n",
    "    confusion = BinaryConfusionMatrix(config.num_class)\n",
    "    \n",
    "    # Iterate over dataset\n",
    "    for i, batch in enumerate(tqdm(dataloader)):\n",
    "\n",
    "        # Move tensors to GPU\n",
    "        if len(config.gpus) > 0:\n",
    "            batch = [t.cuda() for t in batch]\n",
    "        \n",
    "        # Predict class occupancy scores and compute loss\n",
    "        image, calib, labels, mask = batch\n",
    "        with torch.no_grad():\n",
    "            if config.model == 'ved':\n",
    "                logits, mu, logvar = model(image)\n",
    "                loss = criterion(logits, labels, mask, mu, logvar)\n",
    "            else:\n",
    "                logits = model(image, calib)\n",
    "                loss = criterion(logits, labels, mask)\n",
    "\n",
    "        # Update confusion matrix\n",
    "        scores = logits.cpu().sigmoid()  \n",
    "        confusion.update(scores > config.score_thresh, labels, mask)\n",
    "\n",
    "        # Update tensorboard\n",
    "        if i % config.log_interval == 0:\n",
    "            summary.add_scalar('val/loss', float(loss), epoch)\n",
    "        \n",
    "        # Visualise\n",
    "        if i % config.vis_interval == 0:\n",
    "            visualise(summary, image, scores, labels, mask, epoch, \n",
    "                      config.train_dataset, split='val')\n",
    "\n",
    "    # Print and record results\n",
    "    display_results(confusion, config.train_dataset)\n",
    "    log_results(confusion, config.train_dataset, summary, 'val', epoch)\n",
    "\n",
    "    return confusion.mean_iou\n",
    "\n",
    "\n",
    "def visualise(summary, image, scores, labels, mask, step, dataset, split):\n",
    "\n",
    "    class_names = NUSCENES_CLASS_NAMES if dataset == 'nuscenes' \\\n",
    "        else ARGOVERSE_CLASS_NAMES\n",
    "\n",
    "    summary.add_image(split + '/image', image[0], step, dataformats='CHW')\n",
    "    summary.add_image(split + '/pred', colorise(scores[0], 'coolwarm', 0, 1),\n",
    "                      step, dataformats='NHWC')\n",
    "    summary.add_image(split + '/gt', colorise(labels[0], 'coolwarm', 0, 1),\n",
    "                      step, dataformats='NHWC')\n",
    "\n",
    "    \n",
    "    # for i, name in enumerate(class_names):\n",
    "    #     summary.add_image(split + '/pred/' + name, scores[0, i], step, \n",
    "    #                       dataformats='HW')\n",
    "    #     summary.add_image(split + '/gt/' + name, labels[0, i], step, \n",
    "    #                       dataformats='HW')\n",
    "    \n",
    "    # summary.add_image(split + '/mask', mask[0], step, dataformats='HW')\n",
    "\n",
    "\n",
    "def display_results(confusion, dataset):\n",
    "\n",
    "    # Display confusion matrix summary\n",
    "    class_names = NUSCENES_CLASS_NAMES if dataset == 'nuscenes' \\\n",
    "        else ARGOVERSE_CLASS_NAMES\n",
    "    \n",
    "    print('\\nResults:')\n",
    "    for name, iou_score in zip(class_names, confusion.iou):\n",
    "        print('{:20s} {:.3f}'.format(name, iou_score)) \n",
    "    print('{:20s} {:.3f}'.format('MEAN', confusion.mean_iou))\n",
    "\n",
    "\n",
    "\n",
    "def log_results(confusion, dataset, summary, split, epoch):\n",
    "\n",
    "    # Display and record epoch IoU scores\n",
    "    class_names = NUSCENES_CLASS_NAMES if dataset == 'nuscenes' \\\n",
    "        else ARGOVERSE_CLASS_NAMES\n",
    "\n",
    "    for name, iou_score in zip(class_names, confusion.iou):\n",
    "        summary.add_scalar(f'{split}/iou/{name}', iou_score, epoch)\n",
    "    summary.add_scalar(f'{split}/iou/MEAN', confusion.mean_iou, epoch)\n",
    "\n",
    "\n",
    "\n",
    "def save_checkpoint(path, model, optimizer, scheduler, epoch, best_iou):\n",
    "\n",
    "    if isinstance(model, nn.DataParallel):\n",
    "        model = model.module\n",
    "    \n",
    "    ckpt = {\n",
    "        'model' : model.state_dict(),\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "        'scheduler' : scheduler.state_dict(),\n",
    "        'epoch' : epoch,\n",
    "        'best_iou' : best_iou\n",
    "    }\n",
    "\n",
    "    torch.save(ckpt, path)\n",
    "\n",
    "\n",
    "def load_checkpoint(path, model, optimizer, scheduler):\n",
    "    \n",
    "    ckpt = torch.load(path)\n",
    "\n",
    "    # Load model weights\n",
    "    if isinstance(model, nn.DataParallel):\n",
    "        model = model.module\n",
    "    model.load_state_dict(ckpt['model'])\n",
    "\n",
    "    # Load optimiser state\n",
    "    optimizer.load_state_dict(ckpt['optimizer'])\n",
    "\n",
    "    # Load scheduler state\n",
    "    scheduler.load_state_dict(ckpt['scheduler'])\n",
    "\n",
    "    return ckpt['epoch'], ckpt['best_iou']\n",
    "\n",
    "\n",
    "\n",
    "# Load the configuration for this experiment\n",
    "def get_configuration(args):\n",
    "\n",
    "    # Load config defaults\n",
    "    config = get_default_configuration()\n",
    "\n",
    "    # Load dataset options\n",
    "    config.merge_from_file(f'configs/datasets/{args.dataset}.yml')\n",
    "\n",
    "    # Load model options\n",
    "    config.merge_from_file(f'configs/models/{args.model}.yml')\n",
    "\n",
    "    # Load experiment options\n",
    "    config.merge_from_file(f'configs/experiments/{args.experiment}.yml')\n",
    "\n",
    "    # Restore config from an existing experiment\n",
    "    if args.resume is not None:\n",
    "        config.merge_from_file(os.path.join(args.resume, 'config.yml'))\n",
    "    \n",
    "    # Override with command line options\n",
    "    config.merge_from_list(args.options)\n",
    "\n",
    "    # Finalise config\n",
    "    config.freeze()\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "def create_experiment(config, tag, resume=None):\n",
    "\n",
    "    # Restore an existing experiment if a directory is specified\n",
    "    if resume is not None:\n",
    "        print(\"\\n==> Restoring experiment from directory:\\n\" + resume)\n",
    "        logdir = resume\n",
    "    else:\n",
    "        # Otherwise, generate a run directory based on the current time\n",
    "        name = datetime.now().strftime('{}_%y-%m-%d--%H-%M-%S').format(tag)\n",
    "        logdir = os.path.join(os.path.expandvars(config.logdir), name)\n",
    "        print(\"\\n==> Creating new experiment in directory:\\n\" + logdir)\n",
    "        os.makedirs(logdir)\n",
    "    \n",
    "    # Display the config options on-screen\n",
    "    print(config.dump())\n",
    "    \n",
    "    # Save the current config\n",
    "    with open(os.path.join(logdir, 'config.yml'), 'w') as f:\n",
    "        f.write(config.dump())\n",
    "    \n",
    "    return logdir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_137581/585711985.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Set default device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Setup experiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bev/lib/python3.8/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mset_device\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_device_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_setDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bev/lib/python3.8/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.argv = ['']\n",
    "parser = ArgumentParser()\n",
    "\n",
    "args = parser.parse_args()\n",
    "args.dataset = 'argoverse'\n",
    "args.model = 'pyramid'\n",
    "args.resume = 'logs/run_21-11-24--16-55-15_one_sequence_one_camera'\n",
    "args.experiment = 'test'\n",
    "args.options = []\n",
    "\n",
    "# Load configuration\n",
    "config = get_configuration(args)\n",
    "\n",
    "# Set default device\n",
    "if len(config.gpus) > 0:\n",
    "    torch.cuda.set_device(config.gpus[0])\n",
    "\n",
    "# Setup experiment\n",
    "model = build_model(config.model, config)\n",
    "train_loader, val_loader = build_dataloaders(config.train_dataset, config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_137581/3966582401.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/mono-semantic-maps/src/models/model_factory.py\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(model_name, config)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bev/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \"\"\"\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bev/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bev/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bev/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bev/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \"\"\"\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bev/lib/python3.8/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "model = build_model(config.model, config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bev",
   "language": "python",
   "name": "bev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
